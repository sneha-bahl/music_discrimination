{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generating Piano Music with Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_z3MKj46EM3y"
      },
      "source": [
        "This notebook has been taken from URL. : https://magenta.tensorflow.org/piano-transformer\n",
        "\n",
        "\n",
        "It is a part of the Demo for the MusicTransformer model. ALL RIGHTS ARE RESERVED TO THE AUTHOR\n",
        "\n",
        "It has been modified slightly just to create a dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-RWsbrhmPpP"
      },
      "source": [
        "##### Copyright 2019 Google LLC.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI5g-x4foZls"
      },
      "source": [
        "# Generating Piano Music with Transformer\n",
        "\n",
        "This Colab notebook lets you play with pretrained [Transformer](https://arxiv.org/abs/1706.03762) models for piano music generation, based on the [Music Transformer](http://g.co/magenta/music-transformer) model introduced by [Huang et al.](https://arxiv.org/abs/1809.04281) in 2018.\n",
        "\n",
        "The models used here were trained on over 10,000 hours of piano recordings from YouTube, transcribed using [Onsets and Frames](http://g.co/magenta/onsets-frames) and represented using the event vocabulary from [Performance RNN](http://g.co/magenta/performance-rnn).\n",
        "\n",
        "Unlike the original Music Transformer paper, this notebook uses attention based on absolute instead of relative position; we may add models that use relative attention at some point in the future."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfrzUsECcONR"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDMQbHPYVKmV"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tciXVi5eWG_1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e1e19db-7f8e-4408-a60e-d187af98c76b"
      },
      "source": [
        "#@title Setup Environment\n",
        "#@markdown Copy some auxiliary data from Google Cloud Storage.\n",
        "#@markdown Also install and import Python dependencies needed\n",
        "#@markdown for running the Transformer models.\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "print('Copying Salamander piano SoundFont (via https://sites.google.com/site/soundfonts4u) from GCS...')\n",
        "!gsutil -q -m cp -r gs://magentadata/models/music_transformer/primers/* /content/\n",
        "!gsutil -q -m cp gs://magentadata/soundfonts/Yamaha-C5-Salamander-JNv5.1.sf2 /content/\n",
        "\n",
        "print('Installing dependencies...')\n",
        "!apt-get update -qq && apt-get install -qq libfluidsynth1 build-essential libasound2-dev libjack-dev\n",
        "!pip install -q 'tensorflow-datasets < 4.0.0'\n",
        "!pip install -qU google-cloud magenta pyfluidsynth\n",
        "\n",
        "print('Importing libraries...')\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "from tensor2tensor import models\n",
        "from tensor2tensor import problems\n",
        "from tensor2tensor.data_generators import text_encoder\n",
        "from tensor2tensor.utils import decoding\n",
        "from tensor2tensor.utils import trainer_lib\n",
        "\n",
        "from magenta.models.score2perf import score2perf\n",
        "import note_seq\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying Salamander piano SoundFont (via https://sites.google.com/site/soundfonts4u) from GCS...\n",
            "Installing dependencies...\n",
            "Importing libraries...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3URxzTQyXfdO"
      },
      "source": [
        "#@title Definitions\n",
        "#@markdown Define a few constants and helper functions.\n",
        "\n",
        "SF2_PATH = '/content/Yamaha-C5-Salamander-JNv5.1.sf2'\n",
        "SAMPLE_RATE = 16000\n",
        "\n",
        "# Upload a MIDI file and convert to NoteSequence.\n",
        "def upload_midi():\n",
        "  data = list(files.upload().values())\n",
        "  if len(data) > 1:\n",
        "    print('Multiple files uploaded; using only one.')\n",
        "  return note_seq.midi_to_note_sequence(data[0])\n",
        "\n",
        "# Decode a list of IDs.\n",
        "def decode(ids, encoder):\n",
        "  ids = list(ids)\n",
        "  if text_encoder.EOS_ID in ids:\n",
        "    ids = ids[:ids.index(text_encoder.EOS_ID)]\n",
        "  return encoder.decode(ids)\n",
        "  "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl3oY0w8gBJh"
      },
      "source": [
        "# Piano Performance Language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBngSJvP_En7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ba5e92d-907a-4373-8701-dcf8bf32eb7a"
      },
      "source": [
        "#@title Setup and Load Checkpoint\n",
        "#@markdown Set up generation from an unconditional Transformer\n",
        "#@markdown model.\n",
        "\n",
        "model_name = 'transformer'\n",
        "hparams_set = 'transformer_tpu'\n",
        "ckpt_path = 'gs://magentadata/models/music_transformer/checkpoints/unconditional_model_16.ckpt'\n",
        "\n",
        "class PianoPerformanceLanguageModelProblem(score2perf.Score2PerfProblem):\n",
        "  @property\n",
        "  def add_eos_symbol(self):\n",
        "    return True\n",
        "\n",
        "problem = PianoPerformanceLanguageModelProblem()\n",
        "unconditional_encoders = problem.get_feature_encoders()\n",
        "\n",
        "# Set up HParams.\n",
        "hparams = trainer_lib.create_hparams(hparams_set=hparams_set)\n",
        "trainer_lib.add_problem_hparams(hparams, problem)\n",
        "hparams.num_hidden_layers = 16\n",
        "hparams.sampling_method = 'random'\n",
        "\n",
        "# Set up decoding HParams.\n",
        "decode_hparams = decoding.decode_hparams()\n",
        "decode_hparams.alpha = 0.0\n",
        "decode_hparams.beam_size = 1\n",
        "\n",
        "# Create Estimator.\n",
        "run_config = trainer_lib.create_run_config(hparams)\n",
        "estimator = trainer_lib.create_estimator(\n",
        "    model_name, hparams, run_config,\n",
        "    decode_hparams=decode_hparams)\n",
        "\n",
        "# Create input generator (so we can adjust priming and\n",
        "# decode length on the fly).\n",
        "def input_generator():\n",
        "  global targets\n",
        "  global decode_length\n",
        "  while True:\n",
        "    yield {\n",
        "        'targets': np.array([targets], dtype=np.int32),\n",
        "        'decode_length': np.array(decode_length, dtype=np.int32)\n",
        "    }\n",
        "\n",
        "# These values will be changed by subsequent cells.\n",
        "targets = []\n",
        "decode_length = 0\n",
        "\n",
        "# Start the Estimator, loading from the specified checkpoint.\n",
        "input_fn = decoding.make_input_fn_from_generator(input_generator())\n",
        "unconditional_samples = estimator.predict(\n",
        "    input_fn, checkpoint_path=ckpt_path)\n",
        "\n",
        "# \"Burn\" one.\n",
        "_ = next(unconditional_samples)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:schedule=continuous_train_and_eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:schedule=continuous_train_and_eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:worker_gpu=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:worker_gpu=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:sync=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:sync=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:datashard_devices: ['gpu:0']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:datashard_devices: ['gpu:0']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:caching_devices: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:caching_devices: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:ps_devices: ['gpu:0']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:ps_devices: ['gpu:0']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpueclo_4x\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpueclo_4x\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fce3d226790>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_log_step_count_steps': 100, '_protocol': None, '_session_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 0.95\n",
            "}\n",
            "allow_soft_placement: true\n",
            "graph_options {\n",
            "  optimizer_options {\n",
            "    global_jit_level: OFF\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_save_checkpoints_steps': 1000, '_keep_checkpoint_max': 20, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/tmpueclo_4x', '_session_creation_timeout_secs': 7200, 'use_tpu': False, 't2t_device_info': {'num_async_replicas': 1}, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fce3d226810>}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fce3d226790>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_log_step_count_steps': 100, '_protocol': None, '_session_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 0.95\n",
            "}\n",
            "allow_soft_placement: true\n",
            "graph_options {\n",
            "  optimizer_options {\n",
            "    global_jit_level: OFF\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_save_checkpoints_steps': 1000, '_keep_checkpoint_max': 20, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/tmpueclo_4x', '_session_creation_timeout_secs': 7200, 'use_tpu': False, 't2t_device_info': {'num_async_replicas': 1}, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fce3d226810>}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7fce46fb0320>) includes params argument, but params are not passed to Estimator.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7fce46fb0320>) includes params argument, but params are not passed to Estimator.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Setting T2TModel mode to 'infer'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Setting T2TModel mode to 'infer'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Setting hparams.dropout to 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Setting hparams.dropout to 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
            "Exception ignored in: <generator object Estimator.predict at 0x7fce46fd8a50>\n",
            "Traceback (most recent call last):\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_estimator/python/estimator/estimator.py\", line 650, in predict\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 130, in __exit__\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 5484, in get_controller\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/eager/context.py\", line 237, in pop\n",
            "IndexError: pop from empty list\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Greedy Decoding\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Greedy Decoding\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from gs://magentadata/models/music_transformer/checkpoints/unconditional_model_16.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Restoring parameters from gs://magentadata/models/music_transformer/checkpoints/unconditional_model_16.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hL-a0x2FSaR",
        "outputId": "cb65a8dd-79e0-49b5-84ff-4d49b2464358"
      },
      "source": [
        "## mount drive to save the midi files\n",
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrqviXrQGAKY"
      },
      "source": [
        "# Generate midi files from Scratch\n",
        "### We are generating around 1600 files from scratch. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1ybYgKSgIt-"
      },
      "source": [
        "### Generate x midi files \n",
        "x = 1600 \n",
        "for i in range(x):\n",
        "  targets = []\n",
        "  decode_length = 1024\n",
        "\n",
        "  # Generate sample events.\n",
        "  sample_ids = next(unconditional_samples)['outputs']\n",
        "\n",
        "  # Decode to NoteSequence.\n",
        "  midi_filename = decode(\n",
        "    sample_ids,\n",
        "    encoder=unconditional_encoders['targets'])\n",
        "  unconditional_ns = note_seq.midi_file_to_note_sequence(midi_filename)\n",
        "\n",
        "  ###################### CHANGE PATH WHEN NEEDED\n",
        "  name = \"/content/drive/MyDrive/music_data/midi/generated_midi/%s.midi\" % i\n",
        "  note_seq.sequence_proto_to_midi_file(\n",
        "    unconditional_ns, name)"
      ],
      "execution_count": 5,
      "outputs": []
    }
  ]
}